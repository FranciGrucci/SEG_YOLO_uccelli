ABSTRACT

Monitoring bird populations in natural habitats is fundamental for ecological research and wildlife conservation. Traditional observation methods rely heavily on manual inspection of large volumes of imagery, which is both time-consuming and prone to observer bias, especially when birds appear small or partially occluded in high-resolution scenes. In this work, we present a deep learningâ€“based pipeline for automated bird detection and segmentation in ultra-high-resolution images. Our method leverages a YOLOv8 model trained on a custom dataset of wild birds, combined with a tiling/slicing strategy specifically designed to preserve small-object visibility in large-format images. The dataset was split using an 80/10/10 train/validation/test ratio, and custom hyperparameters were introduced to improve convergence on highly imbalanced scenes.
To handle the resolution constraints typical of field imagery, we adopt a windowing approach that crops images into overlapping tiles before inference, while preserving and remapping original bounding boxes and masks for accurate training supervision. Experimental results demonstrate promising detection and segmentation performance, showing the viability of YOLOv8 for fine-grained bird localization under real-world environmental conditions. The proposed workflow automates a previously manual process, enabling scalable and efficient bird population monitoring and supporting long-term ecological observation efforts.



# Bird Detection and Segmentation with YOLOv8 and SAHI
*Francesca Grucci*

This repository contains the implementation of a bird detection and instance segmentation pipeline using **YOLOv8** and **SAHI (Slicing Aided Hyper Inference)** for improved performance on high-resolution images with small objects.

---



## Dataset

The dataset is organized in a standard YOLO format with images and corresponding labels:

- **Train/Val/Test split:** 80% / 10% / 10%
- **Counts:**  
  - Train: 102060 images  
  - Validation: 12757 images  
  - Test: 12758 images  
- **Classes:** `["bird"]`

The dataset YAML (`dataset.yaml`) is automatically created and contains paths to images, number of classes (in this case 1), and class names ('bird').

dataset/
â”œâ”€â”€ images/
â”‚ â”œâ”€â”€ train/
â”‚ â”œâ”€â”€ val/
â”‚ â””â”€â”€ test/
â”œâ”€â”€ labels/
â”‚ â”œâ”€â”€ train/
â”‚ â”œâ”€â”€ val/
â”‚ â””â”€â”€ test/
â””â”€â”€ dataset.yaml

The `dataset.yaml` file contains the paths to train, val, and test images, along with the class names.

---

The YOLOv8n model was trained for **2 epochs** (for testing purposes; full training can be extended) with the following parameters:

- **Model:** `yolov8n.pt`
- **Image size:** 1024
- **Batch size:** 4
- **Device:** GPU 
- **Epochs:** 2 (for test run, MUST be increased for final training)
- **Hyperparameters:**
  - Learning rate (`lr0`): 0.001 and (`lrf`):  0.01
  - Momentum: 0.937
  - Weight decay: 0.0005
  - Box loss gain: 7.5
  - Class loss gain: 0.5
  - DFL loss gain: 1.5

Training logs and weights are stored in:

/mnt/Atlante/SEG_YOLO_uccelli/dataset/uccello_exp



---

## Segmentation and Slicing with SAHI

To handle high-resolution images and small birds, **SAHI** is used for slicing the images during inference:

- **Instance Segmentation:** YOLOv8 predicts both bounding boxes and segmentation masks.
- **Slicing:** Images are divided into overlapping tiles to detect small birds accurately.
- **Merging:** Predictions from all slices are merged to form full-image results.
- **Advantage:** Preserves fine details and improves detection and segmentation metrics without resizing the entire image.



---
### Segmentation Label Generation

The segmentation labels are created using a script that performs the following steps:

1. **Parse contours:**  
   Each camera has a `CAM*_countorns.dat` file containing coordinates of detected objects. These are read and stored in memory.

2. **Build polygons:**  
   - **Alphashape** is used to create concave polygons if installed.  
   - **Shapely** can generate convex hulls.  
   - A fallback **monotone chain convex hull algorithm** ensures a polygon is always created.

3. **Normalize coordinates:**  
   Polygon points are scaled to `[0,1]` relative to the image dimensions (`3840x2400`).

4. **Write YOLOv8 `.txt` label files:**  
   - Format: `<class_id> x1 y1 x2 y2 x3 y3 ... xn yn`  
   - Empty polygons are discarded.  
   - Atomic file writing ensures safety.

5. **Process multiple cameras:**  
   - Images are processed sequentially for CAM1, CAM2, CAM3.  
  

---

## SAHI Slicing

Large images can miss small objects if processed directly. SAHI improves inference as follows:

1. **Slice images:**  
   Images are divided into overlapping tiles.

2. **Run YOLOv8 inference per tile:**  
   Each slice is processed independently to detect small objects accurately.

3. **Merge results:**  
   Overlapping predictions are combined, and duplicates are removed using non-max suppression.  
   The final output is a set of polygons corresponding to the original image.

---

## Installation

To run this project, install the required packages:

```bash

pip install ultralytics sahi matplotlib

```

#### Evaluaion

After training, the model is evaluated on the test set


Precision: 0.864

Recall: 0.800

mAP50: 0.858

mAP50-95: 0.473


Metrics are saved and visualized automatically in /mnt/Atlante/SEG_YOLO_uccelli/dataset/plots:

Precision-Recall Curve

mAP50 per class

##### Usage

1. Clone the repository and prepare your dataset in YOLO format (images + .txt labels).

2. Adjust parameters in the script YoLo.py:

EPOCHS = 2
IMGSZ = 1024
BATCH_SIZE = 4
DEVICE = 0  # GPU 0, CPU=-1
MODEL_NAME = "yolov8n.pt"

3. Run

python YoLo.py

###### Results


The following metrics were obtained after a 2-epoch test run on the **test set**:

| Metric       | Value  |
|-------------|--------|
| Precision   | 0.864  |
| Recall      | 0.800  |
| mAP50       | 0.858  |
| mAP50-95    | 0.473  |

The model demonstrates good detection and segmentation performance even on small objects, thanks to the combination of YOLOv8 and SAHI slicing.

![Precision-Recall Curve](plots/precision_recall_curve.png)
![mAP50 per Class](plots/mAP50_per_class.png)


### ðŸ“Š Final Results (20 epochs)

Il modello Ã¨ stato addestrato per 20 epoche su YOLOv8n con slicing SAHI su immagini 1024Ã—1024.
Rispetto al test iniziale a 2 epoche, le metriche sono migliorate sensibilmente, indicando un training stabile e progressivo senza overfitting.

| Metric     | Value |
|-----------|--------|
| Precision | 0.927 |
| Recall    | 0.861 |
| mAP50     | 0.936 |
| mAP50-95  | 0.612 |

Questi valori confermano che il modello Ã¨ in grado di generalizzare bene anche su immagini non viste.

---

## Pipeline Overview

High-level workflow of the bird segmentation and detection pipeline:

Images (High-Res) 
       â”‚
       â–¼
Segmentation Label Generation
       â”‚
       â”œâ”€ Parse contours (`CAM*_countorns.dat`)
       â”œâ”€ Build polygons (Alphashape / Shapely / Convex Hull)
       â””â”€ Normalize coordinates & write YOLOv8 `.txt` labels
       â”‚
       â–¼
SAHI Slicing (Optional for inference)
       â”‚
       â”œâ”€ Slice large images into tiles
       â”œâ”€ Run YOLOv8 inference per tile
       â””â”€ Merge overlapping predictions
       â”‚
       â–¼
YOLOv8 Training (Segmentation)
       â”‚
       â”œâ”€ Pretrained model: `yolov8n.pt`
       â”œâ”€ Dataset: Train / Val / Test split
       â”œâ”€ Hyperparameters: AdamW, batch=4, img=1024
       â””â”€ Output: Model weights & metrics
       â”‚
       â–¼
Evaluation & Results
       â”‚
       â””â”€ Precision / Recall / mAP metrics





##### Source
@misc{Grucci2025BirdYOLO,
  title={Bird Segmentation via YOLOv8},
  author={Grucci Francesca},
  year={2025},
  note={University project, custom dataset}
}



